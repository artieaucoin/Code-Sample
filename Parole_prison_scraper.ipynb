{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to scrape parole data \n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_repsonse():\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # To store scraped data\n",
    "    ids = []\n",
    "    name = []\n",
    "    offense = []\n",
    "    date = []\n",
    "    result = []\n",
    "\n",
    "    #Loop through last 12 months of data\n",
    "    for i in range(11):\n",
    "\n",
    "        j = i + 2\n",
    "\n",
    "        #Create url string to feed webdriver\n",
    "        string = 'li[data-original-index=\"' + str(j) + '\"]'\n",
    "\n",
    "        driver.get(\Link Hidden)\n",
    "\n",
    "        #Locate Dropdown Menu\n",
    "        element = driver.find_element(By.CSS_SELECTOR, \"button.dropdown-toggle\")\n",
    "        element.click()\n",
    "\n",
    "        #Locate Corresponding Month\n",
    "        dropdown_menu = driver.find_element(By.CSS_SELECTOR, 'div.dropdown-menu')\n",
    "        item = dropdown_menu.find_element(By.CSS_SELECTOR, string)\n",
    "        item.click()\n",
    "\n",
    "        #Locate Search Button\n",
    "        search = driver.find_element(By.CSS_SELECTOR, 'div.col-sm-offset-3')\n",
    "        search.click()\n",
    "\n",
    "        #Bring all elements into view\n",
    "        view_all = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'a.viewall')))\n",
    "        view_all.click()\n",
    "\n",
    "        #Get HTML attribute of table\n",
    "        table_element = wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'table-results-1'))).get_attribute('outerHTML')\n",
    "\n",
    "        #Parse table using bs4\n",
    "        table = BeautifulSoup(table_element, 'html.parser')\n",
    "\n",
    "        #Get all rows and corresponding text fields, append in corresponding lists\n",
    "        tr_rows = table.find_all('tr')\n",
    "        tr_rows.pop(0)\n",
    "        for tr_row in tr_rows:\n",
    "            td_entries = tr_row.find_all('td')\n",
    "            ids.append(td_entries[0].get_text())\n",
    "            name.append(td_entries[1].get_text())\n",
    "            offense.append(td_entries[2].get_text())\n",
    "            date.append(td_entries[3].get_text())\n",
    "            result.append(td_entries[4].get_text())\n",
    "\n",
    "\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return ids, name, offense, date, result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script and functions to scrape pdfs with additional data on each parolee\n",
    "import re\n",
    "\n",
    "#The following 6 functions extract race, sex, citizenship, etc from the text scraped from the pdf\n",
    "\n",
    "def extract_citizenship(text):\n",
    "    pattern = rf\"CITIZENSHIP:\\s*(.+)\\b[Dd]orm\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def extract_sex(text):\n",
    "    pattern = rf\"SEX:\\s*(.+)\\bSCDC\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def extract_race(text):\n",
    "    pattern = rf\"RACE:\\s*(.+)\\bSID\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def extract_weight(text):\n",
    "    pattern = rf\"WEIGHT:\\s*(.+)\\blbs\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def extract_height(text):\n",
    "    pattern = rf\"HEIGHT:\\s*(.+)\\bOFFENDER TYPE\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "def extract_age(text):\n",
    "    pattern = rf\"AGE:\\s*(.+)\\bLOCATION\\b\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "#Scrape the pdfs#\n",
    "def scrape_pdfs():\n",
    "    #For scraped data\n",
    "    final_ids = []\n",
    "    age = []\n",
    "    weight = []\n",
    "    height = []\n",
    "    sex = []\n",
    "    race = []\n",
    "    citizenship = []\n",
    "\n",
    "    import pdfplumber\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    #loop through pdfs, named according to the parolee ID number\n",
    "\n",
    "    for id in tqdm(ids):\n",
    "\n",
    "        #find pdf according to parolee ID number\n",
    "        pdf_path = f'PDFs\\{id}.pdf'\n",
    "\n",
    "        text = ''\n",
    "\n",
    "        try:\n",
    "\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                #Get text from pdf\n",
    "                text += pdf.pages[0].extract_text()\n",
    "\n",
    "            #Add scraped race, sex, citizenship, etc to respective initialized lists\n",
    "            final_ids.append(id)\n",
    "            age.append(extract_age(text))\n",
    "            weight.append(extract_weight(text))\n",
    "            height.append(extract_height(text))\n",
    "            sex.append(extract_sex(text))\n",
    "            race.append(extract_race(text))\n",
    "            citizenship.append(extract_citizenship(text))\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            final_ids.append(id)\n",
    "            age.append(None)\n",
    "            weight.append(None)\n",
    "            height.append(None)\n",
    "            sex.append(None)\n",
    "            race.append(None)\n",
    "            citizenship.append(None)\n",
    "            \n",
    "    return final_ids, age, weight, height, sex, race, citizenship"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
